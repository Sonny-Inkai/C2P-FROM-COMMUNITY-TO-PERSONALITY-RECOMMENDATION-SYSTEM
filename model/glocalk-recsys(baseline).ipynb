{"metadata":{"colab":{"provenance":[],"include_colab_link":true},"gpuClass":"standard","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7732166,"sourceType":"datasetVersion","datasetId":4518303}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/fleanend/TorchGlocalK/blob/main/Glocal_K.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"cell_type":"code","source":"from time import time\nfrom scipy.sparse import csc_matrix\nimport numpy as np\nimport h5py\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.parameter import Parameter\n\ntorch.manual_seed(1284)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nimport pandas as pd","metadata":{"id":"nl2tU6kL8Ot3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"379fe638-9ba3-4513-c9d0-6bbd279e03e2","execution":{"iopub.status.busy":"2024-03-01T22:45:52.786016Z","iopub.execute_input":"2024-03-01T22:45:52.786450Z","iopub.status.idle":"2024-03-01T22:45:53.149122Z","shell.execute_reply.started":"2024-03-01T22:45:52.786420Z","shell.execute_reply":"2024-03-01T22:45:53.148217Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Data Loader Function","metadata":{"id":"k4A9uU1WloQ2"}},{"cell_type":"code","source":"ratings = pd.read_csv('/kaggle/input/the-movie-datasets/new_ratings_small.csv')\nratings","metadata":{"execution":{"iopub.status.busy":"2024-03-01T22:45:54.073905Z","iopub.execute_input":"2024-03-01T22:45:54.074507Z","iopub.status.idle":"2024-03-01T22:45:54.216798Z","shell.execute_reply.started":"2024-03-01T22:45:54.074475Z","shell.execute_reply":"2024-03-01T22:45:54.215659Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"       userId  movieId  rating   timestamp\n0           1       31     2.5  1260759144\n1           1     1029     3.0  1260759179\n2           1     1061     3.0  1260759182\n3           1     1129     2.0  1260759185\n4           1     1172     4.0  1260759205\n...       ...      ...     ...         ...\n99805     671     6268     2.5  1065579370\n99806     671     6269     4.0  1065149201\n99807     671     6365     4.0  1070940363\n99808     671     6385     2.5  1070979663\n99809     671     6565     3.5  1074784724\n\n[99810 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>31</td>\n      <td>2.5</td>\n      <td>1260759144</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1029</td>\n      <td>3.0</td>\n      <td>1260759179</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1061</td>\n      <td>3.0</td>\n      <td>1260759182</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1129</td>\n      <td>2.0</td>\n      <td>1260759185</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1172</td>\n      <td>4.0</td>\n      <td>1260759205</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>99805</th>\n      <td>671</td>\n      <td>6268</td>\n      <td>2.5</td>\n      <td>1065579370</td>\n    </tr>\n    <tr>\n      <th>99806</th>\n      <td>671</td>\n      <td>6269</td>\n      <td>4.0</td>\n      <td>1065149201</td>\n    </tr>\n    <tr>\n      <th>99807</th>\n      <td>671</td>\n      <td>6365</td>\n      <td>4.0</td>\n      <td>1070940363</td>\n    </tr>\n    <tr>\n      <th>99808</th>\n      <td>671</td>\n      <td>6385</td>\n      <td>2.5</td>\n      <td>1070979663</td>\n    </tr>\n    <tr>\n      <th>99809</th>\n      <td>671</td>\n      <td>6565</td>\n      <td>3.5</td>\n      <td>1074784724</td>\n    </tr>\n  </tbody>\n</table>\n<p>99810 rows Ã— 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"movie_ids = np.unique(ratings.movieId.to_numpy().astype(int))","metadata":{"execution":{"iopub.status.busy":"2024-03-01T22:45:54.893772Z","iopub.execute_input":"2024-03-01T22:45:54.894175Z","iopub.status.idle":"2024-03-01T22:45:54.903831Z","shell.execute_reply.started":"2024-03-01T22:45:54.894144Z","shell.execute_reply":"2024-03-01T22:45:54.902731Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def reindex(movie_id): \n    normal_id = np.where(movie_ids == movie_id)[0][0]\n    return normal_id","metadata":{"execution":{"iopub.status.busy":"2024-03-01T22:45:55.643871Z","iopub.execute_input":"2024-03-01T22:45:55.644261Z","iopub.status.idle":"2024-03-01T22:45:55.652293Z","shell.execute_reply.started":"2024-03-01T22:45:55.644231Z","shell.execute_reply":"2024-03-01T22:45:55.651213Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"np.loadtxt('/kaggle/input/the-movie-datasets/train_data.csv', skiprows=1, delie)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data_100k(path, delimiter=','):\n\n    train = np.loadtxt(path+'train_data.csv', skiprows=1, delimiter=delimiter)\n    test = np.loadtxt(path+'test_data.csv', skiprows=1, delimiter=delimiter)\n    eval = np.loadtxt(path+'val_data.csv', skiprows=1, delimiter=delimiter)\n    total = np.concatenate((train, test, eval), axis=0)\n\n    n_u = np.unique(total[:,0]).size  # num of users\n    n_m = np.unique(total[:,1]).size  # num of movies\n    n_train = train.shape[0]  # num of training ratings\n    n_test = test.shape[0]  # num of test ratings\n\n    train_r = np.zeros((n_m, n_u), dtype='float32')\n    test_r = np.zeros((n_m, n_u), dtype='float32')\n    eval_r = np.zeros((n_m, n_u), dtype='float32')\n    \n    for i in range(train.shape[0]):\n        train_r[reindex(train[i][1])][int(train[i][0])-1] = train[i][2]\n    \n    for i in range(test.shape[0]):\n        test_r[reindex(test[i][1])][int(test[i][0])-1] = test[i][2]\n        \n    for i in range(eval.shape[0]):\n        eval_r[reindex(eval[i][1])][int(eval[i][0])-1] = eval[i][2]\n\n    train_m = np.greater(train_r, 1e-12).astype('float32')  # masks indicating non-zero entries\n    test_m = np.greater(test_r, 1e-12).astype('float32')\n\n    print('data matrix loaded')\n    print('num of users: {}'.format(n_u))\n    print('num of movies: {}'.format(n_m))\n    print('num of training ratings: {}'.format(n_train))\n    print('num of test ratings: {}'.format(n_test))\n\n    return n_m, n_u, train_r, train_m, test_r, test_m","metadata":{"execution":{"iopub.status.busy":"2024-03-01T22:58:16.304958Z","iopub.execute_input":"2024-03-01T22:58:16.305341Z","iopub.status.idle":"2024-03-01T22:58:16.318668Z","shell.execute_reply.started":"2024-03-01T22:58:16.305313Z","shell.execute_reply":"2024-03-01T22:58:16.317718Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# Load Data","metadata":{"id":"E_8kEkg9mlIW"}},{"cell_type":"code","source":"# Insert the path of a data directory by yourself (e.g., '/content/.../data')\n# .-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\ndata_path = ''\n# .-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._","metadata":{"id":"0fkA1WpmipzF","execution":{"iopub.status.busy":"2024-03-01T22:58:17.190989Z","iopub.execute_input":"2024-03-01T22:58:17.191357Z","iopub.status.idle":"2024-03-01T22:58:17.197320Z","shell.execute_reply.started":"2024-03-01T22:58:17.191332Z","shell.execute_reply":"2024-03-01T22:58:17.196143Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Data Load\ntry:\n    path = '/kaggle/input/the-movie-datasets/'\n    n_m, n_u, train_r, train_m, test_r, test_m = load_data_100k(path=path, delimiter=',')\nexcept Exception:\n    print('Error: Unable to load data')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sJqSSY33mgkw","outputId":"54f7ca43-b9f7-4edb-8628-783a4513f4f6","execution":{"iopub.status.busy":"2024-03-01T22:58:30.624645Z","iopub.execute_input":"2024-03-01T22:58:30.625065Z","iopub.status.idle":"2024-03-01T22:58:32.700131Z","shell.execute_reply.started":"2024-03-01T22:58:30.625026Z","shell.execute_reply":"2024-03-01T22:58:32.698802Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"data matrix loaded\nnum of users: 671\nnum of movies: 9025\nnum of training ratings: 93100\nnum of test ratings: 3355\n","output_type":"stream"}]},{"cell_type":"code","source":"# Common hyperparameter settings\nn_hid = 500 # size of hidden layers\nn_dim = 5 # inner AE embedding size\nn_layers = 2 # number of hidden layers\ngk_size = 3 # width=height of kernel for convolution\n\n# Hyperparameters to tune for specific case\nmax_epoch_p = 500 # max number of epochs for pretraining\nmax_epoch_f = 1000 # max number of epochs for finetuning\npatience_p = 5 # number of consecutive rounds of early stopping condition before actual stop for pretraining\npatience_f = 10 # and finetuning\ntol_p = 1e-4 # minimum threshold for the difference between consecutive values of train rmse, used for early stopping, for pretraining\ntol_f = 1e-5 # and finetuning\nlambda_2 = 20. # regularisation of number or parameters\nlambda_s = 0.006 # regularisation of sparsity of the final matrix\ndot_scale = 1 # dot product weight for global kernel","metadata":{"id":"nGCdp_FlobOK","execution":{"iopub.status.busy":"2024-03-01T23:02:04.491323Z","iopub.execute_input":"2024-03-01T23:02:04.491975Z","iopub.status.idle":"2024-03-01T23:02:04.497942Z","shell.execute_reply.started":"2024-03-01T23:02:04.491945Z","shell.execute_reply":"2024-03-01T23:02:04.496853Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"# Network Functions","metadata":{"id":"5sWtU4-pmDDT"}},{"cell_type":"code","source":"def local_kernel(u, v):\n    dist = torch.norm(u - v, p=2, dim=2)\n    hat = torch.clamp(1. - dist**2, min=0.)\n    return hat\n\nclass KernelLayer(nn.Module):\n    def __init__(self, n_in, n_hid, n_dim, lambda_s, lambda_2, activation=nn.Sigmoid()):\n      super().__init__()\n      self.W = nn.Parameter(torch.randn(n_in, n_hid))\n      self.u = nn.Parameter(torch.randn(n_in, 1, n_dim))\n      self.v = nn.Parameter(torch.randn(1, n_hid, n_dim))\n      self.b = nn.Parameter(torch.randn(n_hid))\n\n      self.lambda_s = lambda_s\n      self.lambda_2 = lambda_2\n\n      nn.init.xavier_uniform_(self.W, gain=torch.nn.init.calculate_gain(\"relu\"))\n      nn.init.xavier_uniform_(self.u, gain=torch.nn.init.calculate_gain(\"relu\"))\n      nn.init.xavier_uniform_(self.v, gain=torch.nn.init.calculate_gain(\"relu\"))\n      nn.init.zeros_(self.b)\n      self.activation = activation\n\n    def forward(self, x):\n      w_hat = local_kernel(self.u, self.v)\n    \n      sparse_reg = torch.nn.functional.mse_loss(w_hat, torch.zeros_like(w_hat))\n      sparse_reg_term = self.lambda_s * sparse_reg\n      \n      l2_reg = torch.nn.functional.mse_loss(self.W, torch.zeros_like(self.W))\n      l2_reg_term = self.lambda_2 * l2_reg\n\n      W_eff = self.W * w_hat  # Local kernelised weight matrix\n      y = torch.matmul(x, W_eff) + self.b\n      y = self.activation(y)\n\n      return y, sparse_reg_term + l2_reg_term\n\nclass KernelNet(nn.Module):\n    def __init__(self, n_u, n_hid, n_dim, n_layers, lambda_s, lambda_2):\n      super().__init__()\n      layers = []\n      for i in range(n_layers):\n        if i == 0:\n          layers.append(KernelLayer(n_u, n_hid, n_dim, lambda_s, lambda_2))\n        else:\n          layers.append(KernelLayer(n_hid, n_hid, n_dim, lambda_s, lambda_2))\n      layers.append(KernelLayer(n_hid, n_u, n_dim, lambda_s, lambda_2, activation=nn.Identity()))\n      self.layers = nn.ModuleList(layers)\n      self.dropout = nn.Dropout(0.33)\n\n    def forward(self, x):\n      total_reg = None\n      for i, layer in enumerate(self.layers):\n        x, reg = layer(x)\n        if i < len(self.layers)-1:\n          x = self.dropout(x)\n        if total_reg is None:\n          total_reg = reg\n        else:\n          total_reg += reg\n      return x, total_reg","metadata":{"id":"p1P6fgYiy28F","execution":{"iopub.status.busy":"2024-03-01T23:02:05.360133Z","iopub.execute_input":"2024-03-01T23:02:05.361049Z","iopub.status.idle":"2024-03-01T23:02:05.376933Z","shell.execute_reply.started":"2024-03-01T23:02:05.360982Z","shell.execute_reply":"2024-03-01T23:02:05.375919Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"class CompleteNet(nn.Module):\n    def __init__(self, kernel_net, n_u, n_m, n_hid, n_dim, n_layers, lambda_s, lambda_2, gk_size, dot_scale):\n      super().__init__()\n      self.gk_size = gk_size\n      self.dot_scale = dot_scale\n      self.local_kernel_net = kernel_net\n      self.conv_kernel = torch.nn.Parameter(torch.randn(n_m, gk_size**2) * 0.1)\n      nn.init.xavier_uniform_(self.conv_kernel, gain=torch.nn.init.calculate_gain(\"relu\"))\n      \n\n    def forward(self, x, x_local):\n      gk = self.global_kernel(x_local, self.gk_size, self.dot_scale)\n      x = self.global_conv(x, gk)\n      x, global_reg_loss = self.local_kernel_net(x)\n      return x, global_reg_loss\n\n    def global_kernel(self, input, gk_size, dot_scale):\n      avg_pooling = torch.mean(input, dim=1)  # Item (axis=1) based average pooling\n      avg_pooling = avg_pooling.view(1, -1)\n\n      gk = torch.matmul(avg_pooling, self.conv_kernel) * dot_scale  # Scaled dot product\n      gk = gk.view(1, 1, gk_size, gk_size)\n\n      return gk\n\n    def global_conv(self, input, W):\n      input = input.unsqueeze(0).unsqueeze(0)\n      conv2d = nn.LeakyReLU()(F.conv2d(input, W, stride=1, padding=1))\n      return conv2d.squeeze(0).squeeze(0)\n\nclass Loss(nn.Module):\n    def forward(self, pred_p, reg_loss, train_m, train_r):\n      # L2 loss\n      diff = train_m * (train_r - pred_p)\n      sqE = torch.nn.functional.mse_loss(diff, torch.zeros_like(diff))\n      loss_p = sqE + reg_loss\n      return loss_p","metadata":{"id":"7RGKh1ckXgtP","execution":{"iopub.status.busy":"2024-03-01T23:02:05.513126Z","iopub.execute_input":"2024-03-01T23:02:05.513767Z","iopub.status.idle":"2024-03-01T23:02:05.525610Z","shell.execute_reply.started":"2024-03-01T23:02:05.513736Z","shell.execute_reply":"2024-03-01T23:02:05.524656Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"# Network Instantiation","metadata":{"id":"f8sQCwrSmKG4"}},{"cell_type":"markdown","source":"## Pre-training","metadata":{"id":"zOtWj1SCo1RW"}},{"cell_type":"code","source":"model = KernelNet(n_u, n_hid, n_dim, n_layers, lambda_s, lambda_2).double().to(device)","metadata":{"id":"7teUrgWagpW0","execution":{"iopub.status.busy":"2024-03-01T23:02:06.254039Z","iopub.execute_input":"2024-03-01T23:02:06.254395Z","iopub.status.idle":"2024-03-01T23:02:06.484598Z","shell.execute_reply.started":"2024-03-01T23:02:06.254371Z","shell.execute_reply":"2024-03-01T23:02:06.483393Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"## Fine-tuning","metadata":{"id":"4IEBsNhNo4Cj"}},{"cell_type":"code","source":"complete_model = CompleteNet(model, n_u, n_m, n_hid, n_dim, n_layers, lambda_s, lambda_2, gk_size, dot_scale).double().to(device)","metadata":{"id":"OiTXqnN6zLXQ","execution":{"iopub.status.busy":"2024-03-01T23:02:07.594618Z","iopub.execute_input":"2024-03-01T23:02:07.595393Z","iopub.status.idle":"2024-03-01T23:02:07.610038Z","shell.execute_reply.started":"2024-03-01T23:02:07.595358Z","shell.execute_reply":"2024-03-01T23:02:07.608535Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation code","metadata":{"id":"sETwz58aK6y6"}},{"cell_type":"code","source":"def dcg_k(score_label, k):\n    dcg, i = 0., 0\n    for s in score_label:\n        if i < k:\n            dcg += (2**s[1]-1) / np.log2(2+i)\n            i += 1\n    return dcg","metadata":{"id":"vyReXxgac3KH","execution":{"iopub.status.busy":"2024-03-01T23:02:07.903888Z","iopub.execute_input":"2024-03-01T23:02:07.904775Z","iopub.status.idle":"2024-03-01T23:02:07.909820Z","shell.execute_reply.started":"2024-03-01T23:02:07.904739Z","shell.execute_reply":"2024-03-01T23:02:07.908859Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def ndcg_k(y_hat, y, k):\n    score_label = np.stack([y_hat, y], axis=1).tolist()\n    score_label = sorted(score_label, key=lambda d:d[0], reverse=True)\n    score_label_ = sorted(score_label, key=lambda d:d[1], reverse=True)\n    norm, i = 0., 0\n    for s in score_label_:\n        if i < k:\n            norm += (2**s[1]-1) / np.log2(2+i)\n            i += 1\n    dcg = dcg_k(score_label, k)\n    return dcg / norm","metadata":{"id":"jwsSR-8ZdGWo","execution":{"iopub.status.busy":"2024-03-01T23:02:09.910973Z","iopub.execute_input":"2024-03-01T23:02:09.912038Z","iopub.status.idle":"2024-03-01T23:02:09.918823Z","shell.execute_reply.started":"2024-03-01T23:02:09.912004Z","shell.execute_reply":"2024-03-01T23:02:09.917803Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def call_ndcg(y_hat, y):\n    ndcg_sum, num = 0, 0\n    y_hat, y = y_hat.T, y.T\n    n_users = y.shape[0]\n\n    for i in range(n_users):\n        y_hat_i = y_hat[i][np.where(y[i])]\n        y_i = y[i][np.where(y[i])]\n\n        if y_i.shape[0] < 2:\n            continue\n\n        ndcg_sum += ndcg_k(y_hat_i, y_i, y_i.shape[0])  # user-wise calculation\n        num += 1\n\n    return ndcg_sum / num","metadata":{"id":"yy9eQS51pbhj","execution":{"iopub.status.busy":"2024-03-01T23:02:10.323178Z","iopub.execute_input":"2024-03-01T23:02:10.323676Z","iopub.status.idle":"2024-03-01T23:02:10.331128Z","shell.execute_reply.started":"2024-03-01T23:02:10.323647Z","shell.execute_reply":"2024-03-01T23:02:10.329948Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"# Training and Test Loop","metadata":{"id":"RXXQjeMxmYEC"}},{"cell_type":"code","source":"best_rmse_ep, best_mae_ep, best_ndcg_ep = 0, 0, 0\nbest_rmse, best_mae, best_ndcg = float(\"inf\"), float(\"inf\"), 0\n\ntime_cumulative = 0\ntic = time()\n\n# Pre-Training\noptimizer = torch.optim.AdamW(complete_model.local_kernel_net.parameters(), lr=0.001)\n\ndef closure():\n  optimizer.zero_grad()\n  x = torch.Tensor(train_r).double().to(device)\n  m = torch.Tensor(train_m).double().to(device)\n  complete_model.local_kernel_net.train()\n  pred, reg = complete_model.local_kernel_net(x)\n  loss = Loss().to(device)(pred, reg, m, x)\n  loss.backward()\n  return loss\n\nlast_rmse = np.inf\ncounter = 0\n\nfor i in range(max_epoch_p):\n  optimizer.step(closure)\n  complete_model.local_kernel_net.eval()\n  t = time() - tic\n  time_cumulative += t\n\n  pre, _ = model(torch.Tensor(train_r).double().to(device))\n  \n  pre = pre.float().cpu().detach().numpy()\n  \n  error = (test_m * (np.clip(pre, 1., 5.) - test_r) ** 2).sum() / test_m.sum()  # test error\n  test_rmse = np.sqrt(error)\n\n  error_train = (train_m * (np.clip(pre, 1., 5.) - train_r) ** 2).sum() / train_m.sum()  # train error\n  train_rmse = np.sqrt(error_train)\n\n  if last_rmse-train_rmse < tol_p:\n    counter += 1\n  else:\n    counter = 0\n\n  last_rmse = train_rmse\n\n  if patience_p == counter:\n    print('.-^-._' * 12)\n    print('PRE-TRAINING')\n    print('Epoch:', i+1, 'test rmse:', test_rmse, 'train rmse:', train_rmse)\n    print('Time:', t, 'seconds')\n    print('Time cumulative:', time_cumulative, 'seconds')\n    print('.-^-._' * 12)\n    break\n\n\n  if i % 50 != 0:\n    continue\n  print('.-^-._' * 12)\n  print('PRE-TRAINING')\n  print('Epoch:', i, 'test rmse:', test_rmse, 'train rmse:', train_rmse)\n  print('Time:', t, 'seconds')\n  print('Time cumulative:', time_cumulative, 'seconds')\n  print('.-^-._' * 12)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UZ35Zoha-Eue","outputId":"4fc0c647-b0a5-4e69-afff-899c14dc247d","execution":{"iopub.status.busy":"2024-03-01T23:02:10.612228Z","iopub.execute_input":"2024-03-01T23:02:10.613075Z","iopub.status.idle":"2024-03-01T23:02:18.655133Z","shell.execute_reply.started":"2024-03-01T23:02:10.613041Z","shell.execute_reply":"2024-03-01T23:02:18.654029Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\nPRE-TRAINING\nEpoch: 0 test rmse: 2.8489468 train rmse: 2.7043576\nTime: 3.6166112422943115 seconds\nTime cumulative: 3.6166112422943115 seconds\n.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\nPRE-TRAINING\nEpoch: 30 test rmse: 1.1394981 train rmse: 1.0339878\nTime: 7.946157217025757 seconds\nTime cumulative: 174.03898167610168 seconds\n.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n","output_type":"stream"}]},{"cell_type":"code","source":"# Fine-Tuning\n\ntrain_r_local = np.clip(pre, 1., 5.)\n\noptimizer = torch.optim.AdamW(complete_model.parameters(), lr=0.001)\n\ndef closure():\n  optimizer.zero_grad()\n  x = torch.Tensor(train_r).double().to(device)\n  x_local = torch.Tensor(train_r_local).double().to(device)\n  m = torch.Tensor(train_m).double().to(device)\n  complete_model.train()\n  pred, reg = complete_model(x, x_local)\n  loss = Loss().to(device)(pred, reg, m, x)\n  loss.backward()\n  return loss\n\nlast_rmse = np.inf\ncounter = 0\n\nfor i in range(max_epoch_f):\n  optimizer.step(closure)\n  complete_model.eval()\n  t = time() - tic\n  time_cumulative += t\n\n  pre, _ = complete_model(torch.Tensor(train_r).double().to(device), torch.Tensor(train_r_local).double().to(device))\n  \n  pre = pre.float().cpu().detach().numpy()\n\n  error = (test_m * (np.clip(pre, 1., 5.) - test_r) ** 2).sum() / test_m.sum()  # test error\n  test_rmse = np.sqrt(error)\n\n  error_train = (train_m * (np.clip(pre, 1., 5.) - train_r) ** 2).sum() / train_m.sum()  # train error\n  train_rmse = np.sqrt(error_train)\n\n  test_mae = (test_m * np.abs(np.clip(pre, 1., 5.) - test_r)).sum() / test_m.sum()\n  train_mae = (train_m * np.abs(np.clip(pre, 1., 5.) - train_r)).sum() / train_m.sum()\n\n  test_ndcg = call_ndcg(np.clip(pre, 1., 5.), test_r)\n  train_ndcg = call_ndcg(np.clip(pre, 1., 5.), train_r)\n\n  if test_rmse < best_rmse:\n      best_rmse = test_rmse\n      best_rmse_ep = i+1\n\n  if test_mae < best_mae:\n      best_mae = test_mae\n      best_mae_ep = i+1\n\n  if best_ndcg < test_ndcg:\n      best_ndcg = test_ndcg\n      best_ndcg_ep = i+1\n\n  if last_rmse-train_rmse < tol_f:\n    counter += 1\n  else:\n    counter = 0\n\n  last_rmse = train_rmse\n\n  if patience_f == counter:\n    print('.-^-._' * 12)\n    print('FINE-TUNING')\n    print('Epoch:', i+1, 'test rmse:', test_rmse, 'test mae:', test_mae, 'test ndcg:', test_ndcg)\n    print('Epoch:', i+1, 'train rmse:', train_rmse, 'train mae:', train_mae, 'train ndcg:', train_ndcg)\n    print('Time:', t, 'seconds')\n    print('Time cumulative:', time_cumulative, 'seconds')\n    print('.-^-._' * 12)\n    break\n\n\n  if i % 50 != 0:\n    continue\n\n  print('.-^-._' * 12)\n  print('FINE-TUNING')\n  print('Epoch:', i, 'test rmse:', test_rmse, 'test mae:', test_mae, 'test ndcg:', test_ndcg)\n  print('Epoch:', i, 'train rmse:', train_rmse, 'train mae:', train_mae, 'train ndcg:', train_ndcg)\n  print('Time:', t, 'seconds')\n  print('Time cumulative:', time_cumulative, 'seconds')\n  print('.-^-._' * 12)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i6v_tODcweLn","outputId":"5ab3f058-5c7c-458a-c3b5-32bbcf4df418","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_test_ratings(test_data):\n    test_ratings = []\n    list_test_ratings = [np.take(test_data[:, i], np.where(test_data[:, i] != 0)[0]) for i in range(test_data.shape[1])]\n    for i in list_test_ratings:\n        test_ratings.extend(i.flatten().tolist())\n    return test_ratings","metadata":{"id":"b6Yfh3hm4Efa","execution":{"iopub.status.busy":"2024-03-01T23:24:12.914041Z","iopub.execute_input":"2024-03-01T23:24:12.915090Z","iopub.status.idle":"2024-03-01T23:24:12.921217Z","shell.execute_reply.started":"2024-03-01T23:24:12.915046Z","shell.execute_reply":"2024-03-01T23:24:12.920040Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"test_ratings = get_test_ratings(test_data=test_r)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T23:24:15.094951Z","iopub.execute_input":"2024-03-01T23:24:15.095358Z","iopub.status.idle":"2024-03-01T23:24:15.185077Z","shell.execute_reply.started":"2024-03-01T23:24:15.095330Z","shell.execute_reply":"2024-03-01T23:24:15.184207Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"test_ratings[:10]","metadata":{"execution":{"iopub.status.busy":"2024-03-01T23:24:23.380912Z","iopub.execute_input":"2024-03-01T23:24:23.381330Z","iopub.status.idle":"2024-03-01T23:24:23.388202Z","shell.execute_reply.started":"2024-03-01T23:24:23.381299Z","shell.execute_reply":"2024-03-01T23:24:23.386947Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"[2.5, 3.0, 3.5, 2.0, 2.5, 4.0, 4.0, 4.0, 4.0, 5.0]"},"metadata":{}}]},{"cell_type":"code","source":"pre, _ = model(torch.Tensor(train_r).double().to(device))\n\nX_local_train = pre.float().cpu().detach().numpy()","metadata":{"execution":{"iopub.status.busy":"2024-03-01T23:24:27.622613Z","iopub.execute_input":"2024-03-01T23:24:27.623800Z","iopub.status.idle":"2024-03-01T23:24:27.681402Z","shell.execute_reply.started":"2024-03-01T23:24:27.623760Z","shell.execute_reply":"2024-03-01T23:24:27.680470Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"item_user_ratings, _ = complete_model(torch.Tensor(train_r).double().to(device), torch.Tensor(X_local_train).double().to(device))","metadata":{"execution":{"iopub.status.busy":"2024-03-01T23:24:28.836172Z","iopub.execute_input":"2024-03-01T23:24:28.836578Z","iopub.status.idle":"2024-03-01T23:24:28.913550Z","shell.execute_reply.started":"2024-03-01T23:24:28.836546Z","shell.execute_reply":"2024-03-01T23:24:28.912637Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"item_user_ratings = item_user_ratings.cpu().detach().numpy()","metadata":{"execution":{"iopub.status.busy":"2024-03-01T23:27:31.553966Z","iopub.execute_input":"2024-03-01T23:27:31.554722Z","iopub.status.idle":"2024-03-01T23:27:31.602634Z","shell.execute_reply.started":"2024-03-01T23:27:31.554688Z","shell.execute_reply":"2024-03-01T23:27:31.601755Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"item_user_ratings","metadata":{"execution":{"iopub.status.busy":"2024-03-01T23:27:32.522135Z","iopub.execute_input":"2024-03-01T23:27:32.522549Z","iopub.status.idle":"2024-03-01T23:27:32.530155Z","shell.execute_reply.started":"2024-03-01T23:27:32.522519Z","shell.execute_reply":"2024-03-01T23:27:32.529078Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"array([[1.73074321, 3.63429229, 3.63656566, ..., 3.4269872 , 3.67124289,\n        3.96704491],\n       [1.63262593, 3.35782014, 3.33629337, ..., 3.14282657, 3.35274912,\n        3.61206747],\n       [1.6151962 , 3.30237794, 3.28367413, ..., 3.09725839, 3.30215109,\n        3.55779893],\n       ...,\n       [1.53551611, 3.06810275, 3.04076603, ..., 2.87330462, 3.05196535,\n        3.28282077],\n       [1.56800076, 3.16454811, 3.14013668, ..., 2.96458761, 3.15433328,\n        3.39479814],\n       [1.70047523, 3.54337064, 3.54463115, ..., 3.34324497, 3.57804091,\n        3.86452437]])"},"metadata":{}}]},{"cell_type":"code","source":"def get_test_ratings(item_user_ratings):\n    item_user_ratings = item_user_ratings*test_m\n    predict_ratings = []\n    list_test_ratings = [np.take(item_user_ratings[: ,i], np.where(item_user_ratings[:, i] != 0)[0]) for i in range(item_user_ratings.shape[1])]\n    for i in list_test_ratings:\n        predict_ratings.extend(i.flatten().tolist())\n    return predict_ratings","metadata":{"execution":{"iopub.status.busy":"2024-03-01T23:27:35.190921Z","iopub.execute_input":"2024-03-01T23:27:35.192072Z","iopub.status.idle":"2024-03-01T23:27:35.198593Z","shell.execute_reply.started":"2024-03-01T23:27:35.192021Z","shell.execute_reply":"2024-03-01T23:27:35.197471Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"predict_ratings =  get_test_ratings(item_user_ratings)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T23:27:36.101936Z","iopub.execute_input":"2024-03-01T23:27:36.102376Z","iopub.status.idle":"2024-03-01T23:27:36.182855Z","shell.execute_reply.started":"2024-03-01T23:27:36.102346Z","shell.execute_reply":"2024-03-01T23:27:36.181922Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nmse = mean_squared_error(test_ratings , predict_ratings)\nprint('MSE =',mse)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T23:27:56.234056Z","iopub.execute_input":"2024-03-01T23:27:56.234411Z","iopub.status.idle":"2024-03-01T23:27:56.724374Z","shell.execute_reply.started":"2024-03-01T23:27:56.234386Z","shell.execute_reply":"2024-03-01T23:27:56.723252Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"MSE = 0.9529989632937604\n","output_type":"stream"}]},{"cell_type":"code","source":"import math\nrmse = math.sqrt(mse)\nprint('RMSE =',rmse)     ","metadata":{"execution":{"iopub.status.busy":"2024-03-01T23:28:14.058347Z","iopub.execute_input":"2024-03-01T23:28:14.059051Z","iopub.status.idle":"2024-03-01T23:28:14.065308Z","shell.execute_reply.started":"2024-03-01T23:28:14.059017Z","shell.execute_reply":"2024-03-01T23:28:14.064036Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"RMSE = 0.9762166579677691\n","output_type":"stream"}]}]}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        1,        20,         4, 887431883],\n",
       "       [        1,        33,         4, 878542699],\n",
       "       [        1,        61,         4, 878542420],\n",
       "       ...,\n",
       "       [      943,       570,         1, 888640125],\n",
       "       [      943,       808,         4, 888639868],\n",
       "       [      943,      1067,         2, 875501756]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.loadtxt('..\\\\data\\\\ml-100k\\\\ua.test', skiprows=0, delimiter='\\t').astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, delimiter='\\t'):\n",
    "    train = np.loadtxt(path+'ua.base', skiprows=0, delimiter=delimiter).astype('int32')\n",
    "    test = np.loadtxt(path+'ua.test', skiprows=0, delimiter=delimiter).astype('int32')\n",
    "    total = np.concatenate((train, test), axis=0)\n",
    "\n",
    "    n_u = np.unique(total[:, 0]).size #num of users\n",
    "    n_i = np.unique(total[:, 1]).size #num of items\n",
    "\n",
    "    train_data = np.zeros((n_u, n_i), dtype='float32')\n",
    "    test_data = np.zeros((n_u, n_i), dtype='float32')\n",
    "\n",
    "    for i in range(train.shape[0]):\n",
    "        train_data[train[i][0]-1][train[i][1]-1] = train[i][2]\n",
    "    \n",
    "    for i in range(test.shape[0]):\n",
    "        test_data[test[i][0]-1][test[i][1]-1] = test[i][2]\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = load_data(path='..\\\\data\\\\ml-100k\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3333333333333335"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 1601\n",
    "sum(train_data[:, a])/np.count_nonzero(train_data[:, a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_item_rating(train_data):\n",
    "    list_average_item_rating = [sum(train_data[:, i])/np.count_nonzero(train_data[:, i]) for i in range(train_data.shape[1])]\n",
    "    return list_average_item_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Theba\\AppData\\Local\\Temp\\ipykernel_948\\2928453520.py:2: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  list_average_item_rating = [sum(train_data[:, i])/np.count_nonzero(train_data[:, i]) for i in range(train_data.shape[1])]\n"
     ]
    }
   ],
   "source": [
    "list_average_item_rating = average_item_rating(train_data=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5555555555555554"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_average_item_rating[1183]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_features(item_path): \n",
    "   i_cols = ['movie id', 'movie title' ,'release date','video release date', 'IMDb URL', 'unknown', 'Action', 'Adventure',\n",
    " 'Animation', 'Children\\'s', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    " 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "\n",
    "   movies = pd.read_csv(item_path, sep='|', names=i_cols,encoding='latin-1')\n",
    "   genres = movies[['unknown', 'Action', 'Adventure',\n",
    " 'Animation', 'Children\\'s', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    " 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']]\n",
    "   genres = genres.to_numpy()\n",
    "\n",
    "   return genres\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_featuers = get_item_features('..\\\\data\\\\ml-100k\\\\u.item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_featuers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Theba\\miniconda3\\envs\\venv\\lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1353, in _get_module\n",
      "  File \"c:\\Users\\Theba\\miniconda3\\envs\\venv\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1030, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 986, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 680, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 850, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\n",
      "  File \"c:\\Users\\Theba\\miniconda3\\envs\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\", line 42, in <module>\n",
      "    from ...modeling_utils import PreTrainedModel\n",
      "  File \"c:\\Users\\Theba\\miniconda3\\envs\\venv\\lib\\site-packages\\transformers\\modeling_utils.py\", line 74, in <module>\n",
      "    from .utils.import_utils import ENV_VARS_TRUE_VALUES, importlib_metadata, is_sagemaker_mp_enabled\n",
      "ImportError: cannot import name 'importlib_metadata' from 'transformers.utils.import_utils' (c:\\Users\\Theba\\miniconda3\\envs\\venv\\lib\\site-packages\\transformers\\utils\\import_utils.py)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Theba\\miniconda3\\envs\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3548, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Theba\\AppData\\Local\\Temp\\ipykernel_948\\3230220075.py\", line 2, in <module>\n",
      "    from transformers import BertTokenizer, BertForSequenceClassification\n",
      "  File \"<frozen importlib._bootstrap>\", line 1055, in _handle_fromlist\n",
      "  File \"c:\\Users\\Theba\\miniconda3\\envs\\venv\\lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1344, in __getattr__\n",
      "  File \"c:\\Users\\Theba\\miniconda3\\envs\\venv\\lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1343, in __getattr__\n",
      "  File \"c:\\Users\\Theba\\miniconda3\\envs\\venv\\lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1355, in _get_module\n",
      "RuntimeError: Failed to import transformers.models.bert.modeling_bert because of the following error (look up to see its traceback):\n",
      "cannot import name 'importlib_metadata' from 'transformers.utils.import_utils' (c:\\Users\\Theba\\miniconda3\\envs\\venv\\lib\\site-packages\\transformers\\utils\\import_utils.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Theba\\miniconda3\\envs\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2142, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"c:\\Users\\Theba\\miniconda3\\envs\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"c:\\Users\\Theba\\miniconda3\\envs\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"c:\\Users\\Theba\\miniconda3\\envs\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"c:\\Users\\Theba\\miniconda3\\envs\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"c:\\Users\\Theba\\miniconda3\\envs\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"c:\\Users\\Theba\\miniconda3\\envs\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"c:\\Users\\Theba\\miniconda3\\envs\\venv\\lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\Theba\\miniconda3\\envs\\venv\\lib\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"c:\\Users\\Theba\\miniconda3\\envs\\venv\\lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\Theba\\miniconda3\\envs\\venv\\lib\\site-packages\\stack_data\\core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"c:\\Users\\Theba\\miniconda3\\envs\\venv\\lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\Theba\\miniconda3\\envs\\venv\\lib\\site-packages\\stack_data\\core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"c:\\Users\\Theba\\miniconda3\\envs\\venv\\lib\\site-packages\\executing\\executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1) # 1 label for regression\n",
    "\n",
    "# Sample input description\n",
    "description = \"This product is amazing! It exceeded all my expectations.\"\n",
    "\n",
    "# Tokenize input description\n",
    "inputs = tokenizer(description, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "# Forward pass through the model\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Get predicted rating\n",
    "predicted_rating = outputs.logits.item()\n",
    "\n",
    "print(\"Predicted Rating:\", predicted_rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
